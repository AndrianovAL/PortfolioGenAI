{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fa66dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('src'))\n",
    "\n",
    "from pgai.vector_db_clients import FAISSClient#, ChromaClient\n",
    "from pgai import langchain_helper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c1b596",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d4cb8e",
   "metadata": {},
   "source": [
    "In this example, I am using LangChain to build a simple LLM-powered assistant. I will focus on using:\n",
    "1. Google Gemini\n",
    "2. OpenAI gpt-4o-mini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec980a",
   "metadata": {},
   "source": [
    "# Problem Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48382bba",
   "metadata": {},
   "source": [
    "I'll take a `new_report.txt`, `metrics.csv`, and `training_examples.csv` and use LangChain to:\n",
    "1. Score the new report\n",
    "2. Extract from the new_report 3 pieces of supporting evidence for this Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826ea039",
   "metadata": {},
   "source": [
    "# Initialize LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576be773",
   "metadata": {},
   "source": [
    "First need to initialize an LLM. I'll use _Google Gemini_ or _OpenAI 'gpt-4.1-nano'_ model. You can get an API key from [OpenAI](https://platform.openai.com/settings/organization/api-keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "594dcaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GOOGLE_API_KEY loaded successfully (not printing it for security).\n"
     ]
    }
   ],
   "source": [
    "AI_Provider = \"GOOGLE\"\n",
    "# LLM_Provider = \"OPENAI\"\n",
    "\n",
    "llm, llm_structured = langchain_helper.get_llm(AI_Provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6108c9b",
   "metadata": {},
   "source": [
    "# Create VectorDB from TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5cc5994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report loaded: 303115 characters\n",
      "First 200 characters of the report: 2024\n",
      "Amazon\n",
      "Sustainability\n",
      "Report\n",
      "2\n",
      "Contents\n",
      "Overview 3 Introduction\n",
      "4 A Letter from Our\n",
      "Chief Sustainability\n",
      "Officer\n",
      "5 How We Work\n",
      "6 Goals Summary\n",
      "7 2024 Year in Review\n",
      "Progress 8 Carbon and Energy\n",
      "1...\n",
      "Split into 1451 chunks\n",
      "FAISS index has 1451 vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pgai.vector_db_clients.faiss_client.FAISSClient at 0x7f0ad6ff6270>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_client = FAISSClient()\n",
    "docs = langchain_helper.split_txt_to_docs(txt_path=\"data/new_report_Amazon.txt\")\n",
    "db_client.from_docs(docs)\n",
    "# db = langchain_helper.create_vectordb_from_txt_file(txt_filename=\"new_report_IBM.txt\")\n",
    "# db.save_local(\"data/vector_dbs/faiss_index\")\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")  # This model is small (~80MB), fast on CPU, good for English # Alternative: ultra-fast memory-light (~45MB): model_name=\"sentence-transformers/paraphrase-MiniLM-L3-v2\" # Alternative: embeddings = OpenAIEmbeddings()\n",
    "# db = FAISS.load_local(\"data/vector_dbs/faiss_index\", embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce516c88",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fecc813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "metrics_filename = 'data/metrics.csv'\n",
    "metrics = pd.read_csv(metrics_filename)\n",
    "# print(metrics.iloc[0][\"MetricDescription\"])\n",
    "# metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78857215",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples_filename = 'data/train_examples.csv'\n",
    "train_examples = pd.read_csv(train_examples_filename)\n",
    "# train_examples.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b4c02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "\n",
    "# Defining the system prompt (how the AI should act)\n",
    "system_prompt = SystemMessagePromptTemplate.from_template('You are a sustainability consultant tasked to score a company against the provided metric. Score can be: 1, 2, or 3.')\n",
    "\n",
    "# the user prompt is provided by the user, in this case however the only dynamic input is the article\n",
    "user_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"# You need to score the company \"{new_company}\" against the metric and criteria (provided below) and provide 3 reasons for the score by quoting the report.\n",
    "        ## The output should be a JSON object with the following fields (no other explanation or text or fields are allowed):\n",
    "        - Company: the name of the company\n",
    "        - MetricID: MetricID\n",
    "        - Score: the score of the company\n",
    "        - Reason1: first reason for the score\n",
    "        - Reason2: second reason for the score\n",
    "        - Reason3: third reason for the score\n",
    "    \n",
    "    MetricID: {metric_id}\n",
    "    Scoring criteria: {metric_description}\n",
    "\n",
    "    # Below are examples of the scoring applied to 3 companies:\n",
    "    Company 1: {Company_1}\n",
    "    Score: {Score_1}\n",
    "    Reason 1: {Reason1_1}\n",
    "    Reason 2: {Reason2_1}\n",
    "    Reason 3: {Reason3_1}\n",
    "\n",
    "    Company 2: {Company_2}\n",
    "    Score: {Score_2}\n",
    "    Reason 1: {Reason1_2}\n",
    "    Reason 2: {Reason2_2}\n",
    "    Reason 3: {Reason3_2}\n",
    "\n",
    "    Company 3: {Company_3}\n",
    "    Score: {Score_3}\n",
    "    Reason 1: {Reason1_3}\n",
    "    Reason 2: {Reason2_3}\n",
    "    Reason 3: {Reason3_3}\n",
    "    \n",
    "    # The report of the company \"{new_company}\" is:\n",
    "    {new_company_report_chunks_summary}\n",
    "    \"\"\",\n",
    "\n",
    "    input_variables=[\"metric_id\", \"metric_description\", \"new_company\",\n",
    "        \"Company_1\", \"Score_1\", \"Reason1_1\", \"Reason2_1\", \"Reason3_1\",\n",
    "        \"Company_2\", \"Score_2\", \"Reason1_2\", \"Reason2_2\", \"Reason3_2\",\n",
    "        \"Company_3\", \"Score_3\", \"Reason1_3\", \"Reason2_3\", \"Reason3_3\", \"new_company_report_chunks_summary\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236ba951",
   "metadata": {},
   "source": [
    "Now we can merge the `system` and `user` prompts into a full chat prompt using the `ChatPromptTemplate`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb2cfa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 1: create an article title\n",
    "prompt = ChatPromptTemplate.from_messages([system_prompt, user_prompt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de5ac1e",
   "metadata": {},
   "source": [
    "# Main Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b994818",
   "metadata": {},
   "source": [
    "Now chain the `prompt` template and the `llm` object defined earlier to create an LLM chain for **prompt formatting > llm generation > get output**.\n",
    "\n",
    "Let's use __LCEL__ to construct the chain: define inputs with `{\"metric_id\": lambda x: x[\"metric_id\"], ...}` and use the pipe operator (`|`) to feed the output from its left into the input to its right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "259f2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This chain will output (for the given metric) the new company's score and provides 3 reasons\n",
    "chain = (\n",
    "    {\n",
    "        \"metric_id\": lambda x: x[\"metric_id\"],\n",
    "        \"metric_description\": lambda x: x[\"metric_description\"],\n",
    "        \"new_company\": lambda x: x[\"new_company\"],\n",
    "        \"Company_1\": lambda x: x[\"Company_1\"],\n",
    "        \"Score_1\": lambda x: x[\"Score_1\"],\n",
    "        \"Reason1_1\": lambda x: x[\"Reason1_1\"],\n",
    "        \"Reason2_1\": lambda x: x[\"Reason2_1\"],\n",
    "        \"Reason3_1\": lambda x: x[\"Reason3_1\"],\n",
    "        \"Company_2\": lambda x: x[\"Company_2\"],\n",
    "        \"Score_2\": lambda x: x[\"Score_2\"],\n",
    "        \"Reason1_2\": lambda x: x[\"Reason1_2\"],\n",
    "        \"Reason2_2\": lambda x: x[\"Reason2_2\"],\n",
    "        \"Reason3_2\": lambda x: x[\"Reason3_2\"],\n",
    "        \"Company_3\": lambda x: x[\"Company_3\"],\n",
    "        \"Score_3\": lambda x: x[\"Score_3\"],\n",
    "        \"Reason1_3\": lambda x: x[\"Reason1_3\"],\n",
    "        \"Reason2_3\": lambda x: x[\"Reason2_3\"],\n",
    "        \"Reason3_3\": lambda x: x[\"Reason3_3\"],\n",
    "        \"new_company_report_chunks_summary\": lambda x: x[\"new_company_report_chunks_summary\"]\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_structured\n",
    "    | {\n",
    "        \"Company\": lambda llm_output: llm_output.Company,\n",
    "        \"MetricID\": lambda llm_output: llm_output.MetricID,\n",
    "        \"Score\": lambda llm_output: llm_output.Score,\n",
    "        \"Reason1\": lambda llm_output: llm_output.Reason1,\n",
    "        \"Reason2\": lambda llm_output: llm_output.Reason2,\n",
    "        \"Reason3\": lambda llm_output: llm_output.Reason3\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07a3503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Report loaded (303115 characters).\n",
      "Sample:\n",
      "2024\n",
      "Amazon\n",
      "Sustainability\n",
      "Report\n",
      "2\n",
      "Contents\n",
      "Overview 3 Introduction\n",
      "4 A Letter from Our\n",
      "Chief Sustainability\n",
      "Officer\n",
      "5 How We Work\n",
      "6 Goals Summary\n",
      "7 2024 Year in Review\n",
      "Progress 8 Carbon and Energy\n",
      "1...\n",
      "âœ… Document split into 1451 chunks.\n",
      "âœ… Vector DB created with 1451 vectors.\n"
     ]
    }
   ],
   "source": [
    "company_name = \"Amazon\"\n",
    "db = langchain_helper.create_vectordb_from_txt_file(\n",
    "    txt_filename=f\"data/new_report_{company_name}.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "851d5374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scoring complete. Results saved to 'data/Amazon_scores.csv'.\n"
     ]
    }
   ],
   "source": [
    "new_company_scores = []\n",
    "company_name = \"Amazon\"\n",
    "# Main Scoring Pipeline\n",
    "def run_scoring_pipeline(company_name, metrics, train_examples, db, chain, top_k=3):\n",
    "    results = []\n",
    "    \n",
    "    for metric_id in metrics.MetricID:\n",
    "        query = langchain_helper.prep_similarity_search_query(metrics, metric_id)\n",
    "        report_summary = langchain_helper.similarity_search(query, db, top_k=top_k)\n",
    "        prompt_inputs = langchain_helper.prep_prompt_inputs(company_name, metrics, metric_id, train_examples, report_summary)\n",
    "        result = chain.invoke(prompt_inputs)\n",
    "        results.append(result)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    output_path = f\"data/{company_name}_scores.csv\"\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "    print(f\"âœ… Scoring complete. Results saved to '{output_path}'.\")\n",
    "    return results_df\n",
    "\n",
    "\n",
    "results_df = run_scoring_pipeline(company_name, metrics, train_examples, db, chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5d5dd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>MetricID</th>\n",
       "      <th>Score</th>\n",
       "      <th>Reason1</th>\n",
       "      <th>Reason2</th>\n",
       "      <th>Reason3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>Through The Climate Pledge , which we co-found...</td>\n",
       "      <td>our goal to reach net-zero carbon emissions ac...</td>\n",
       "      <td>We set bold, long-term aspirations, such as Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>Amazon aims to reach net-zero carbon emissions...</td>\n",
       "      <td>Amazon has committed to The Climate Pledge in ...</td>\n",
       "      <td>Amazon measures both absolute emissions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>Amazon has set a net-zero carbon emissions tar...</td>\n",
       "      <td>Through The Climate Pledge, their goal is to r...</td>\n",
       "      <td>They measure and publicly report their carbon ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Scope 2 and 3 carbon emissions are calculated ...</td>\n",
       "      <td>This table includes both on-site solar and con...</td>\n",
       "      <td>We worked with our top suppliers on carbon mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>The report does not provide any information ab...</td>\n",
       "      <td>The report does not provide any information ab...</td>\n",
       "      <td>The report does not provide any information ab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company  MetricID  Score                                            Reason1  \\\n",
       "0  Amazon        11      3  Through The Climate Pledge , which we co-found...   \n",
       "1  Amazon        12      2  Amazon aims to reach net-zero carbon emissions...   \n",
       "2  Amazon        13      3  Amazon has set a net-zero carbon emissions tar...   \n",
       "3  Amazon         5      1  Scope 2 and 3 carbon emissions are calculated ...   \n",
       "4  Amazon         7      1  The report does not provide any information ab...   \n",
       "\n",
       "                                             Reason2  \\\n",
       "0  our goal to reach net-zero carbon emissions ac...   \n",
       "1  Amazon has committed to The Climate Pledge in ...   \n",
       "2  Through The Climate Pledge, their goal is to r...   \n",
       "3  This table includes both on-site solar and con...   \n",
       "4  The report does not provide any information ab...   \n",
       "\n",
       "                                             Reason3  \n",
       "0  We set bold, long-term aspirations, such as Th...  \n",
       "1            Amazon measures both absolute emissions  \n",
       "2  They measure and publicly report their carbon ...  \n",
       "3  We worked with our top suppliers on carbon mea...  \n",
       "4  The report does not provide any information ab...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad28f18",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> __NEXT__ </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51b35d6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
