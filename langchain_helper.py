# from langchain_google_genai import GoogleGenerativeAI  # LLM: Google Gemini
#     # Maybe need:   from langchain_google_genai import ChatGoogleGenerativeAI
# from langchain.prompts import PromptTemplate  # for templates
# from langchain.chains import LLMChain  # chain llm & prompt


#''' Can constrain the number of tokens sent, e.g. limit = 4000 '''
    # if api_key == None:
    #     load_dotenv()
    #     GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
    # else:
    #     GOOGLE_API_KEY = api_key
    # llm = GoogleGenerativeAI(google_api_key=GOOGLE_API_KEY, model="gemini-2.0-flash", temperature=0.2, max_tokens=6_000)
    #     # Maybe need:   llm = ChatGoogleGenerativeAI(google_api_key=GOOGLE_API_KEY, model="gemini-2.0-flash", temperature=0.2, max_tokens=500)
    #     # Alternative:  llm = OpenAI(model_name="text-davinci-003")
 




# if __name__ == "__main__":
#     print(f'Response:\n{}')
